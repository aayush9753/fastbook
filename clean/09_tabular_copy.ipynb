{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "09_tabular.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJB8QTTXENll",
        "outputId": "088ec538-fb42-45a7-c55b-18f3b0ad0327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "#fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 20.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbadd7Lo08D",
        "outputId": "96e220f9-0261-49d0-fc9a-f3bc93e7f1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install kaggle\r\n",
        "!pip install dtreeviz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: dtreeviz in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (1.1.5)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (3.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.90)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (3.0.1)\n",
            "Requirement already satisfied: graphviz>=0.9 in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.10.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dtreeviz) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dtreeviz) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->dtreeviz) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->dtreeviz) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (2.4.7)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark->dtreeviz) (0.10.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (20.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (8.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (51.0.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->dtreeviz) (1.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT0r1dLmHBll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6ab4902f-cd28-46cf-fbf6-fd92dd21f23c"
      },
      "source": [
        "'''!mkdir ~/.kaggle\r\n",
        "!touch ~/.kaggle/kaggle.json\r\n",
        "\r\n",
        "api_token = {\"username\":\"aayush9753\",\"key\":\"c047b423d88d4fbe9d8eb5ba63235ce1\"}\r\n",
        "\r\n",
        "import json\r\n",
        "\r\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\r\n",
        "    json.dump(api_token, file)\r\n",
        "\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!mkdir ~/.kaggle\\n!touch ~/.kaggle/kaggle.json\\n\\napi_token = {\"username\":\"aayush9753\",\"key\":\"c047b423d88d4fbe9d8eb5ba63235ce1\"}\\n\\nimport json\\n\\nwith open(\\'/root/.kaggle/kaggle.json\\', \\'w\\') as file:\\n    json.dump(api_token, file)\\n\\n!chmod 600 ~/.kaggle/kaggle.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp2knkLzENls",
        "outputId": "309d0956-6eb4-404e-a759-ca0ea4cde514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "from kaggle import api\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from dtreeviz.trees import *\n",
        "from IPython.display import Image, display_svg, SVG\n",
        "\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_columns = 8"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ed5c6ffd6b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#hide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[1;32m    165\u001b[0m                               ' {}. Or use the environment method.'.format(\n\u001b[0;32m--> 166\u001b[0;31m                                   self.config_file, self.config_dir))\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Step 3: load into configuration!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDOgmcGtENlt"
      },
      "source": [
        "# Tabular Modeling Deep Dive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ygPQNqENlt"
      },
      "source": [
        "## Categorical Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2f401YfENlu"
      },
      "source": [
        "## Beyond Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ewbfr8rENlu"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOW4A41bENlu"
      },
      "source": [
        "### Kaggle Competitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwT8wDh6ENlv"
      },
      "source": [
        "creds = '{\"username\":\"\",\"key\":\"\"}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYQaewMXENlv"
      },
      "source": [
        "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
        "if not cred_path.exists():\n",
        "    cred_path.parent.mkdir(exist_ok=True)\n",
        "    cred_path.write(creds)\n",
        "    cred_path.chmod(0o600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmZGB9kYENlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49719ec3-2e35-4918-a055-d4283700d4a4"
      },
      "source": [
        "path = URLs.path('bluebook')\n",
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/archive/bluebook')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpaFJq1XENlv"
      },
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mez0Z7qjmud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d804acdb-795c-4e98-e04c-139bdcb67e8a"
      },
      "source": [
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7bvJDw0ENlw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "5a1f99e5-1777-4bf9-bc21-e130491db8ee"
      },
      "source": [
        "if not path.exists():\n",
        "    path.mkdir()\n",
        "    api.competition_download_cli('bluebook-for-bulldozers', path=path)\n",
        "    file_extract(path/'bluebook-for-bulldozers.zip')\n",
        "\n",
        "path.ls(file_type='text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-07cda3b0665a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_download_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bluebook-for-bulldozers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'bluebook-for-bulldozers.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.fastai/archive/bluebook'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoBj12drENlw"
      },
      "source": [
        "### Look at the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDmm4ebIENlx"
      },
      "source": [
        "df = pd.read_csv(path/'TrainAndValid.csv', low_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105FF2X2ENlx"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7XCUUD9ENlx"
      },
      "source": [
        "df['ProductSize'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTGNmaqENlx"
      },
      "source": [
        "sizes = 'Large','Large / Medium','Medium','Small','Mini','Compact'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOgEEY-0ENly"
      },
      "source": [
        "df['ProductSize'] = df['ProductSize'].astype('category')\n",
        "df['ProductSize'].cat.set_categories(sizes, ordered=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMLu05ijENly"
      },
      "source": [
        "dep_var = 'SalePrice'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNGy-G88ENly"
      },
      "source": [
        "df[dep_var] = np.log(df[dep_var])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTQVmtYlENly"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n0v_vBCENlz"
      },
      "source": [
        "### Handling Dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXZhtYyfENlz"
      },
      "source": [
        "df = add_datepart(df, 'saledate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "018WvT3wENlz"
      },
      "source": [
        "df_test = pd.read_csv(path/'Test.csv', low_memory=False)\n",
        "df_test = add_datepart(df_test, 'saledate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfUTgJbxENlz"
      },
      "source": [
        "' '.join(o for o in df.columns if o.startswith('sale'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_s9iO_ENlz"
      },
      "source": [
        "### Using TabularPandas and TabularProc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDIRnphvENl0"
      },
      "source": [
        "procs = [Categorify, FillMissing]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjU-CoINENl0"
      },
      "source": [
        "cond = (df.saleYear<2011) | (df.saleMonth<10)\n",
        "train_idx = np.where( cond)[0]\n",
        "valid_idx = np.where(~cond)[0]\n",
        "\n",
        "splits = (list(train_idx),list(valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giEuTMzBENl0"
      },
      "source": [
        "cont,cat = cont_cat_split(df, 1, dep_var=dep_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaLmWXR_ENl0"
      },
      "source": [
        "to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg6JFSXjENl0"
      },
      "source": [
        "len(to.train),len(to.valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obS38FC7ENl1"
      },
      "source": [
        "to.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0B7S_uYENl1"
      },
      "source": [
        "to1 = TabularPandas(df, procs, ['state', 'ProductGroup', 'Drive_System', 'Enclosure'], [], y_names=dep_var, splits=splits)\n",
        "to1.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mHX7NnIENl1"
      },
      "source": [
        "to.items.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS5PIHcKENl1"
      },
      "source": [
        "to1.items[['state', 'ProductGroup', 'Drive_System', 'Enclosure']].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcY7l7UvENl1"
      },
      "source": [
        "to.classes['ProductSize']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2O5hKxwENl2"
      },
      "source": [
        "(path/'to.pkl').save(to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh2BhoFoENl2"
      },
      "source": [
        "### Creating the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVBgaN1qENl2"
      },
      "source": [
        "#hide\n",
        "to = (path/'to.pkl').load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLjEg-0PENl2"
      },
      "source": [
        "xs,y = to.train.xs,to.train.y\n",
        "valid_xs,valid_y = to.valid.xs,to.valid.y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ONRpDvENl2"
      },
      "source": [
        "m = DecisionTreeRegressor(max_leaf_nodes=4)\n",
        "m.fit(xs, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPkqqeLENl3"
      },
      "source": [
        "draw_tree(m, xs, size=7, leaves_parallel=True, precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amz9dHWRENl3"
      },
      "source": [
        "samp_idx = np.random.permutation(len(y))[:500]\n",
        "dtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n",
        "        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n",
        "        orientation='LR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5mfxV65ENl3"
      },
      "source": [
        "xs.loc[xs['YearMade']<1900, 'YearMade'] = 1950\n",
        "valid_xs.loc[valid_xs['YearMade']<1900, 'YearMade'] = 1950"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI9FJkH2ENl3"
      },
      "source": [
        "m = DecisionTreeRegressor(max_leaf_nodes=4).fit(xs, y)\n",
        "\n",
        "dtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n",
        "        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n",
        "        orientation='LR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44FrhywrENl4"
      },
      "source": [
        "m = DecisionTreeRegressor()\n",
        "m.fit(xs, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPARQgKkENl4"
      },
      "source": [
        "def r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\n",
        "def m_rmse(m, xs, y): return r_mse(m.predict(xs), y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZTvkYTQENl4"
      },
      "source": [
        "m_rmse(m, xs, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gasWluYENl4"
      },
      "source": [
        "m_rmse(m, valid_xs, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNoOETYvENl4"
      },
      "source": [
        "m.get_n_leaves(), len(xs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDXXaw3aENl5"
      },
      "source": [
        "m = DecisionTreeRegressor(min_samples_leaf=25)\n",
        "m.fit(to.train.xs, to.train.y)\n",
        "m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G6IpsSvENl5"
      },
      "source": [
        "m.get_n_leaves()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph6-PK1IENl5"
      },
      "source": [
        "### Categorical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az2UxPD0ENl5"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HAxZ-10ENl5"
      },
      "source": [
        "#hide\n",
        "# pip install —pre -f https://sklearn-nightly.scdn8.secure.raxcdn.com scikit-learn —U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G576YVVKENl6"
      },
      "source": [
        "### Creating a Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQdtbocmENl6"
      },
      "source": [
        "def rf(xs, y, n_estimators=40, max_samples=200_000,\n",
        "       max_features=0.5, min_samples_leaf=5, **kwargs):\n",
        "    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n",
        "        max_samples=max_samples, max_features=max_features,\n",
        "        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1cHhl9BENl6"
      },
      "source": [
        "m = rf(xs, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weXms5vUENl6"
      },
      "source": [
        "m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQVzlu-2ENl7"
      },
      "source": [
        "preds = np.stack([t.predict(valid_xs) for t in m.estimators_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoOXuXRFENl7"
      },
      "source": [
        "r_mse(preds.mean(0), valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNsV_iuOENl7"
      },
      "source": [
        "plt.plot([r_mse(preds[:i+1].mean(0), valid_y) for i in range(40)]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDaOu8jENl7"
      },
      "source": [
        "### Out-of-Bag Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayazAWkxENl7"
      },
      "source": [
        "r_mse(m.oob_prediction_, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soey55rSENl8"
      },
      "source": [
        "## Model Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu0YrqCbENl8"
      },
      "source": [
        "### Tree Variance for Prediction Confidence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GF1AEYvENl8"
      },
      "source": [
        "preds = np.stack([t.predict(valid_xs) for t in m.estimators_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYQhfeWMENl8"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PByBoeFpENl8"
      },
      "source": [
        "preds_std = preds.std(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWKHOumqENl9"
      },
      "source": [
        "preds_std[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKaeuEKAENl9"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkUj3a9GENl9"
      },
      "source": [
        "def rf_feat_importance(m, df):\n",
        "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
        "                       ).sort_values('imp', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5pP87JKENl9"
      },
      "source": [
        "fi = rf_feat_importance(m, xs)\n",
        "fi[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikYp9jYZENl9"
      },
      "source": [
        "def plot_fi(fi):\n",
        "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
        "\n",
        "plot_fi(fi[:30]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Var5M9IDENl-"
      },
      "source": [
        "### Removing Low-Importance Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC7Ub9O_ENl-"
      },
      "source": [
        "to_keep = fi[fi.imp>0.005].cols\n",
        "len(to_keep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHW5qY9mENl-"
      },
      "source": [
        "xs_imp = xs[to_keep]\n",
        "valid_xs_imp = valid_xs[to_keep]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSR3Y86lENl-"
      },
      "source": [
        "m = rf(xs_imp, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG4Z0QyoENl-"
      },
      "source": [
        "m_rmse(m, xs_imp, y), m_rmse(m, valid_xs_imp, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGpXQiBENl_"
      },
      "source": [
        "len(xs.columns), len(xs_imp.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMAle_HTENl_"
      },
      "source": [
        "plot_fi(rf_feat_importance(m, xs_imp));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiXxkuF4ENl_"
      },
      "source": [
        "### Removing Redundant Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGBchHDNENl_"
      },
      "source": [
        "cluster_columns(xs_imp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK3iDeSDENl_"
      },
      "source": [
        "def get_oob(df):\n",
        "    m = RandomForestRegressor(n_estimators=40, min_samples_leaf=15,\n",
        "        max_samples=50000, max_features=0.5, n_jobs=-1, oob_score=True)\n",
        "    m.fit(df, y)\n",
        "    return m.oob_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OmMLMiyENmA"
      },
      "source": [
        "get_oob(xs_imp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d46nQ83UENmA"
      },
      "source": [
        "{c:get_oob(xs_imp.drop(c, axis=1)) for c in (\n",
        "    'saleYear', 'saleElapsed', 'ProductGroupDesc','ProductGroup',\n",
        "    'fiModelDesc', 'fiBaseModel',\n",
        "    'Hydraulics_Flow','Grouser_Tracks', 'Coupler_System')}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl1CESgLENmA"
      },
      "source": [
        "to_drop = ['saleYear', 'ProductGroupDesc', 'fiBaseModel', 'Grouser_Tracks']\n",
        "get_oob(xs_imp.drop(to_drop, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUxI7c4vENmA"
      },
      "source": [
        "xs_final = xs_imp.drop(to_drop, axis=1)\n",
        "valid_xs_final = valid_xs_imp.drop(to_drop, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvQjvB5fENmA"
      },
      "source": [
        "(path/'xs_final.pkl').save(xs_final)\n",
        "(path/'valid_xs_final.pkl').save(valid_xs_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMCdFbnQENmB"
      },
      "source": [
        "xs_final = (path/'xs_final.pkl').load()\n",
        "valid_xs_final = (path/'valid_xs_final.pkl').load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-oUyNBENmB"
      },
      "source": [
        "m = rf(xs_final, y)\n",
        "m_rmse(m, xs_final, y), m_rmse(m, valid_xs_final, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waMIkHEbENmB"
      },
      "source": [
        "### Partial Dependence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57nszzwnENmB"
      },
      "source": [
        "p = valid_xs_final['ProductSize'].value_counts(sort=False).plot.barh()\n",
        "c = to.classes['ProductSize']\n",
        "plt.yticks(range(len(c)), c);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-chldYRENmC"
      },
      "source": [
        "ax = valid_xs_final['YearMade'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j3foIXBENmC"
      },
      "source": [
        "from sklearn.inspection import plot_partial_dependence\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(12, 4))\n",
        "plot_partial_dependence(m, valid_xs_final, ['YearMade','ProductSize'],\n",
        "                        grid_resolution=20, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ygUf8gENmC"
      },
      "source": [
        "### Data Leakage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jYU6dF7ENmC"
      },
      "source": [
        "### Tree Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVKenKOSENmC"
      },
      "source": [
        "#hide\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', FutureWarning)\n",
        "\n",
        "from treeinterpreter import treeinterpreter\n",
        "from waterfall_chart import plot as waterfall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2UjfXKPENmD"
      },
      "source": [
        "row = valid_xs_final.iloc[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5G3wBT2ENmD"
      },
      "source": [
        "prediction,bias,contributions = treeinterpreter.predict(m, row.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTWqBiN8ENmF"
      },
      "source": [
        "prediction[0], bias[0], contributions[0].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaVKbGzcENmF"
      },
      "source": [
        "waterfall(valid_xs_final.columns, contributions[0], threshold=0.08, \n",
        "          rotation_value=45,formatting='{:,.3f}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssKelasRENmF"
      },
      "source": [
        "## Extrapolation and Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAPY6LLqENmF"
      },
      "source": [
        "### The Extrapolation Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xClHHhdEENmF"
      },
      "source": [
        "#hide\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2GW5IfoENmG"
      },
      "source": [
        "x_lin = torch.linspace(0,20, steps=40)\n",
        "y_lin = x_lin + torch.randn_like(x_lin)\n",
        "plt.scatter(x_lin, y_lin);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOAr6MllENmG"
      },
      "source": [
        "xs_lin = x_lin.unsqueeze(1)\n",
        "x_lin.shape,xs_lin.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWzMso34ENmG"
      },
      "source": [
        "x_lin[:,None].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAZPEH6gENmG"
      },
      "source": [
        "m_lin = RandomForestRegressor().fit(xs_lin[:30],y_lin[:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTN-livKENmG"
      },
      "source": [
        "plt.scatter(x_lin, y_lin, 20)\n",
        "plt.scatter(x_lin, m_lin.predict(xs_lin), color='red', alpha=0.5);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkNiwWPAENmH"
      },
      "source": [
        "### Finding Out-of-Domain Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve-VlsIlENmI"
      },
      "source": [
        "df_dom = pd.concat([xs_final, valid_xs_final])\n",
        "is_valid = np.array([0]*len(xs_final) + [1]*len(valid_xs_final))\n",
        "\n",
        "m = rf(df_dom, is_valid)\n",
        "rf_feat_importance(m, df_dom)[:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7qHUK41ENmI"
      },
      "source": [
        "m = rf(xs_final, y)\n",
        "print('orig', m_rmse(m, valid_xs_final, valid_y))\n",
        "\n",
        "for c in ('SalesID','saleElapsed','MachineID'):\n",
        "    m = rf(xs_final.drop(c,axis=1), y)\n",
        "    print(c, m_rmse(m, valid_xs_final.drop(c,axis=1), valid_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQM5bjLENmI"
      },
      "source": [
        "time_vars = ['SalesID','MachineID']\n",
        "xs_final_time = xs_final.drop(time_vars, axis=1)\n",
        "valid_xs_time = valid_xs_final.drop(time_vars, axis=1)\n",
        "\n",
        "m = rf(xs_final_time, y)\n",
        "m_rmse(m, valid_xs_time, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzVLTSYXENmI"
      },
      "source": [
        "xs['saleYear'].hist();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4kofocAENmJ"
      },
      "source": [
        "filt = xs['saleYear']>2004\n",
        "xs_filt = xs_final_time[filt]\n",
        "y_filt = y[filt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DLCGgNaENmJ"
      },
      "source": [
        "m = rf(xs_filt, y_filt)\n",
        "m_rmse(m, xs_filt, y_filt), m_rmse(m, valid_xs_time, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_89NWDkENmJ"
      },
      "source": [
        "### Using a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_fSpFdsENmJ"
      },
      "source": [
        "df_nn = pd.read_csv(path/'TrainAndValid.csv', low_memory=False)\n",
        "df_nn['ProductSize'] = df_nn['ProductSize'].astype('category')\n",
        "df_nn['ProductSize'].cat.set_categories(sizes, ordered=True, inplace=True)\n",
        "df_nn[dep_var] = np.log(df_nn[dep_var])\n",
        "df_nn = add_datepart(df_nn, 'saledate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znt0hzweENmJ"
      },
      "source": [
        "df_nn_final = df_nn[list(xs_final_time.columns) + [dep_var]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eThwyC_KENmK"
      },
      "source": [
        "cont_nn,cat_nn = cont_cat_split(df_nn_final, max_card=9000, dep_var=dep_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xZ8BTl7ENmK"
      },
      "source": [
        "cont_nn.append('saleElapsed')\n",
        "cat_nn.remove('saleElapsed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR2NbyFqENmK"
      },
      "source": [
        "df_nn_final[cat_nn].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-FK-IKCENmK"
      },
      "source": [
        "xs_filt2 = xs_filt.drop('fiModelDescriptor', axis=1)\n",
        "valid_xs_time2 = valid_xs_time.drop('fiModelDescriptor', axis=1)\n",
        "m2 = rf(xs_filt2, y_filt)\n",
        "m_rmse(m, xs_filt2, y_filt), m_rmse(m2, valid_xs_time2, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-CcbGlRENmK"
      },
      "source": [
        "cat_nn.remove('fiModelDescriptor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87exyAulENmL"
      },
      "source": [
        "procs_nn = [Categorify, FillMissing, Normalize]\n",
        "to_nn = TabularPandas(df_nn_final, procs_nn, cat_nn, cont_nn,\n",
        "                      splits=splits, y_names=dep_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ibmmEENmL"
      },
      "source": [
        "dls = to_nn.dataloaders(1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyrjZEdzENmL"
      },
      "source": [
        "y = to_nn.train.y\n",
        "y.min(),y.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCkuN7u_ENmL"
      },
      "source": [
        "from fastai.tabular.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sj4qPInENmL"
      },
      "source": [
        "learn = tabular_learner(dls, y_range=(8,12), layers=[500,250],\n",
        "                        n_out=1, loss_func=F.mse_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deRc9JyYENmM"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pPSR0HHENmM"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94HNtRfENmM"
      },
      "source": [
        "preds,targs = learn.get_preds()\n",
        "r_mse(preds,targs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TRyLB2IENmM"
      },
      "source": [
        "learn.save('nn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWQvInEaENmM"
      },
      "source": [
        "### Sidebar: fastai's Tabular Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ke4OLc1ENmN"
      },
      "source": [
        "### End sidebar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkYvMj9JENmN"
      },
      "source": [
        "## Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNvL4rmBENmN"
      },
      "source": [
        "rf_preds = m.predict(valid_xs_time)\n",
        "ens_preds = (to_np(preds.squeeze()) + rf_preds) /2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcuutjUwENmN"
      },
      "source": [
        "r_mse(ens_preds,valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuL9PVXpENmN"
      },
      "source": [
        "### Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R2VynTfENmN"
      },
      "source": [
        "### Combining Embeddings with Other Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTMmaDnENmO"
      },
      "source": [
        "## Conclusion: Our Advice for Tabular Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIGmzaN2ENmO"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNDRjeOENmO"
      },
      "source": [
        "1. What is a continuous variable?\n",
        "1. What is a categorical variable?\n",
        "1. Provide two of the words that are used for the possible values of a categorical variable.\n",
        "1. What is a \"dense layer\"?\n",
        "1. How do entity embeddings reduce memory usage and speed up neural networks?\n",
        "1. What kinds of datasets are entity embeddings especially useful for?\n",
        "1. What are the two main families of machine learning algorithms?\n",
        "1. Why do some categorical columns need a special ordering in their classes? How do you do this in Pandas?\n",
        "1. Summarize what a decision tree algorithm does.\n",
        "1. Why is a date different from a regular categorical or continuous variable, and how can you preprocess it to allow it to be used in a model?\n",
        "1. Should you pick a random validation set in the bulldozer competition? If no, what kind of validation set should you pick?\n",
        "1. What is pickle and what is it useful for?\n",
        "1. How are `mse`, `samples`, and `values` calculated in the decision tree drawn in this chapter?\n",
        "1. How do we deal with outliers, before building a decision tree?\n",
        "1. How do we handle categorical variables in a decision tree?\n",
        "1. What is bagging?\n",
        "1. What is the difference between `max_samples` and `max_features` when creating a random forest?\n",
        "1. If you increase `n_estimators` to a very high value, can that lead to overfitting? Why or why not?\n",
        "1. In the section \"Creating a Random Forest\", just after <<max_features>>, why did `preds.mean(0)` give the same result as our random forest?\n",
        "1. What is \"out-of-bag-error\"?\n",
        "1. Make a list of reasons why a model's validation set error might be worse than the OOB error. How could you test your hypotheses?\n",
        "1. Explain why random forests are well suited to answering each of the following question:\n",
        "   - How confident are we in our predictions using a particular row of data?\n",
        "   - For predicting with a particular row of data, what were the most important factors, and how did they influence that prediction?\n",
        "   - Which columns are the strongest predictors?\n",
        "   - How do predictions vary as we vary these columns?\n",
        "1. What's the purpose of removing unimportant variables?\n",
        "1. What's a good type of plot for showing tree interpreter results?\n",
        "1. What is the \"extrapolation problem\"?\n",
        "1. How can you tell if your test or validation set is distributed in a different way than your training set?\n",
        "1. Why do we make `saleElapsed` a continuous variable, even although it has less than 9,000 distinct values?\n",
        "1. What is \"boosting\"?\n",
        "1. How could we use embeddings with a random forest? Would we expect this to help?\n",
        "1. Why might we not always use a neural net for tabular modeling?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk56OguhENmO"
      },
      "source": [
        "### Further Research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZRp_NuZENmP"
      },
      "source": [
        "1. Pick a competition on Kaggle with tabular data (current or past) and try to adapt the techniques seen in this chapter to get the best possible results. Compare your results to the private leaderboard.\n",
        "1. Implement the decision tree algorithm in this chapter from scratch yourself, and try it on the datase you used in the first exercise.\n",
        "1. Use the embeddings from the neural net in this chapter in a random forest, and see if you can improve on the random forest results we saw.\n",
        "1. Explain what each line of the source of `TabularModel` does (with the exception of the `BatchNorm1d` and `Dropout` layers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwZPkNcpENmP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}